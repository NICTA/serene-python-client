\def\year{2018}\relax
%File: formatting-instruction.tex
\documentclass[letterpaper]{article} %DO NOT CHANGE THIS
\usepackage{aaai18}  %Required
\usepackage{times}  %Required
\usepackage{helvet}  %Required
\usepackage{courier}  %Required
\usepackage{url}  %Required
\usepackage{graphicx}  %Required
\frenchspacing  %Required
\setlength{\pdfpagewidth}{8.5in}  %Required
\setlength{\pdfpageheight}{11in}  %Required
\usepackage{spverbatim}
\usepackage{fancyvrb}

\usepackage{color}
\usepackage{xcolor}
\usepackage{amsmath,amsthm,stmaryrd}
\usepackage{algpseudocode}
\usepackage{algorithm}
\algrenewcommand\algorithmiccomment[2][\footnotesize]{{#1\hfill\(\triangleright\)
 #2}} %\normalsize
\usepackage{amssymb}
\usepackage{textcomp}

% natalia
\usepackage{subcaption}
\captionsetup{compatibility=false}
\usepackage{multirow}
\usepackage{pgfplots}
\pgfplotsset{width=10cm,compat=1.9}
\usepgfplotslibrary{colorbrewer}

\usepackage{tikz}
\usetikzlibrary{shadows.blur}
\usetikzlibrary{shapes.symbols}
\usetikzlibrary{arrows,shapes,decorations.pathmorphing}
\usetikzlibrary{positioning}
\usetikzlibrary{decorations.text}
\usetikzlibrary{decorations.pathmorphing}
\usetikzlibrary{mindmap,backgrounds}
\tikzstyle{class}=[ellipse,align=center,fill=green!25]
\tikzstyle{data}=[draw,rectangle,align=center,black!70]
\tikzstyle{att}=[rectangle,align=center,fill=brown!70!red]
\tikzstyle{hasaA} = 
[draw,densely dashed,-,black!70,decoration={snake,segment 
length=10,amplitude=1.5,post length=4}]
\tikzstyle{hasaC} = [>=stealth',draw,thick,-, black]
\tikzstyle{isa} = [>=o,draw,densely dotted,very thick,black!90]

\newcommand{\authornote}[3]{
  {\fbox{\sc 
  #1}:$\blacktriangleright$\textcolor{#2}{\small{#3}}$\blacktriangleleft$}%
}
\newcommand{\pds}[1]{\authornote{PDS}{purple}{#1}}
\newcommand{\pjs}[1]{\authornote{PJS}{red}{#1}}
\newcommand{\gkg}[1]{\authornote{GKG}{brown}{#1}}
\newcommand{\ddg}[1]{\authornote{DDG}{blue}{#1}}
\newcommand{\npr}[1]{\authornote{NPR}{orange}{#1}}

\newcommand{\minizinc}{\textsc{MiniZinc}}
\newcommand{\chuffed}{\textsc{Chuffed}}
\newcommand{\relonto}{\textsc{Rel2Onto}}

\newcommand{\etal}{\textit{et al.}}

\newcommand{\code}[1]{\texttt{#1}}

%PDF Info Is Required:

%  \pdfinfo{
%/Title (2018 Formatting Instructions for Authors Using LaTeX)
%/Author (AAAI Press Staff)}
\setcounter{secnumdepth}{2}  
 \begin{document}
% The file aaai.sty is the style file for AAAI Press 
% proceedings, working notes, and technical reports.
%
\title{Machine Learning and Constraint Programming for Relational-To-Ontology Schema Mapping }
\author{}
\maketitle
\begin{abstract}
The problem of integrating heterogeneous data sources in an ontology is of high 
relevance in the database field. Several techniques exist to approach this 
problem. Nonetheless, side constraints on the data integration cannot be easily 
integrated with these tools and thus the results may be inconsistent. We 
present a new approach that combines Machine Learning and 
Constraint Programming techniques, by modelling the data integration problem as 
a Steiner Tree Problem in a weighted graph. We show that through this approach 
we can achieve better precision, recall and speed compared to state-of-the-art 
approaches. We provide a comprehensive set of experiments supporting our 
findings.
\end{abstract}

\section{Introduction}
The problem of integrating heterogeneous data sources is a long standing issue in the database research field and is of high relevance in many real-world domains.
A common approach to tackle this problem is to design a global model and to
construct source descriptions which specify mappings between the sources and
the global model \cite{doan2012principles}.

In our case, we would like this global model to account not only for structural properties of the original data sources, but also to include the semantics, which is usually implicitly present in the sources.
In other words, we want to build a semantic model which describes the data sources in terms of concepts and relationships defined by an ontology \cite{taheriyan2016learning}.
Henceforth, we focus on a specific data integration problem: automatically mapping a new relational data source onto a user provided ontology.

\subsubsection{Example} Consider the situation where we have some simple relational database tables with columns $\langle$\textit{Surname, Workplace, Date, Location}$\rangle$, 
$\langle$\textit{Company, Event, Begin, Until, Location}$\rangle$ and 
$\langle$\textit{Name, D.O.B, Location}$\rangle$.
We do not \textit{a priori} know whether ``Date'' is the date of birth or the date a persons started working in the first table; or whether the ``Location'' on the second table refers to the location of the event, or the address of the company. 
If we are given an ontology like the one in Fig. \ref{FIG:onto}, we would like to automatically map the new data sources to classes of the 
ontology.$\square$

In this paper we use Machine Learning techniques (ML) to learn mapping rules from previously mapped instances.
To this end we formulate the Relational-To-Ontology Mapping Problem (\relonto{}) as a Minimum Cost Steiner Tree Problem (STP) with side constraints \cite{deuna2016steiner}.

Firstly, we build an \emph{integration graph} which includes the 
attributes from the new source as well as ontology classes and properties. 
Secondly, we apply machine learning techniques to 
assign costs to its edges. 
Lastly, we use Constraint Programming (CP) to 
find a minimum cost Steiner Tree in the graph.
The goal is to assign the costs on the edges in such a way that the resulting Steiner Tree is a valid and coherent semantic model for the new source. 

The contributions of this work are:\ddg{TODO}
\begin{itemize}
	\item A novel modeling framework for \relonto{} problem which seemlessly incorporates machine learning and constraint programming.
	\item An efficient approach to handle attributes which cannot be matched to the ontology. \npr{semantic labeling model and root, unknown nodes in the alignment graph and additional constraints} 
\end{itemize}

Section \ref{SEC:pw} presents the previous work done to achieve this task. 
Section \ref{SEC:problem} formally states the problem. 
In Section \ref{SEC:ML} we present how we convert the information given into a 
useful data representation. 
Section \ref{SEC:STP} shows how we model the problem as a STP, 
whereas Section \ref{SEC:CP} discusses how we implement the model in CP. 
Section \ref{SEC:Res} shows our results. 

\section{Problem Statement \label{SEC:problem}}


\begin{figure}[ht]
\centering
\begin{tikzpicture}
	\node[class] (pe) at (0,0)  {Person};
	\node[class] (co) at (0,-3) {Organisation};
	\node[class] (ev) at (3.5,1) {Event};
	\node[class] (pl) at (5,-1) {Place};
	\node[class] (ci) at (3,-3) {City};
	\node[class] (st) at (5,-3) {State};
	
		
	\path[hasaC,->] (pe) edge [bend left= -30] 
	node [midway, above, sloped] {worksFor} (co) ;
	\path[hasaC,->] (co) edge [bend left= -30] 
	node [midway, above, sloped] {ceo} (pe) ;
	
	\path[hasaC,->] (co) edge [] 
	node [midway, above, sloped] {location} (pl) ;
	
	\path[hasaC,->] (pe) edge [bend left = -20] 
	node [midway, above, sloped] {bornIn} (pl) ;
	\path[hasaC,->] (pe) edge [bend left = 0] 
	node [midway, above, sloped] {livesIn} (pl) ;
	
	\path[hasaC,->] (ev) edge [bend left = -20] 
	node [midway, above, sloped] {organizer} (pe) ;
	\path[hasaC,->] (ev) edge [bend left = 0] 
	node [midway, above, sloped] {location} (pl) ;
	
	
	\path[hasaC,->] (pl) edge [out=20,in=0,looseness=8] 
	node [midway, above, sloped] {nearby} (pl) ;
	\path[hasaC,->] (pl) edge [out=45,in=65,looseness=8] 
	node [midway, above, sloped] {partOf} (pl) ;
	
	\path[hasaC,->] (ci) edge  []
	node [midway, above, sloped] {state} (st) ;
	
	\path[isa,->] (ci) -- node [] {} (pl) ;
	\path[isa,->] (st) -- node [] {} (pl) ;
	

	\path[draw,hasaA,->] (pe) edge [decorate,bend left = 10] 
	node [midway, above, sloped] {name} (-0.5,2);
	\path[draw,hasaA,->] (pe) edge [decorate,bend left = 0] 
	node [midway, below, sloped] {birthDate} (0,2);	
	
	\path[draw,hasaA,->] (co) edge [decorate,bend left = 0] 
	node [midway, below, sloped] {name} (-1,-5);
	\path[draw,hasaA,->] (co) edge [decorate,bend left = 0] 
	node [midway, above, sloped] {phone} (0,-5);
	\path[draw,hasaA,->] (co) edge [decorate,bend left = 0] 
	node [midway, above, sloped] {email} (1,-5);
	
	\path[draw,hasaA,->] (ev) edge [decorate,bend left = 0] 
	node [midway, below, sloped] {startDate} (2.5,3.2);
	\path[draw,hasaA,->] (ev) edge [decorate,bend left = 0] 
	node [midway, above, sloped] {endDate} (3.5,3.2);
	\path[draw,hasaA,->] (ev) edge [decorate,bend left = 0] 
	node [midway, below, sloped] {title} (4.5,3.2);
	
	\path[draw,hasaA,->] (pl) edge [decorate,bend left = 0] 
	node [midway, above, sloped] {name} (6.5,-1.8);
	\path[draw,hasaA,->] (pl) edge [decorate,bend left = 0] 
	node [midway, above, sloped] {postalCode} (6,-3);	
	

\end{tikzpicture}
\caption{Example of ontology
(`\tikz{ \node[class] () at (0,0)  {};}' are Classes, `\tikz{ \path[hasaC,->] 
(0,1) -- (3ex,1);}' means ``has a Class property'', 
`\tikz{ \path[hasaA,decoration={post length=0}] (0,0) edge[decorate] (3ex,0);}' 
means ``has 
a data 
property'' and 
`\tikz{ \path[isa,->] (0,1) -- (3ex,1);}' means ``is a'' ). Based on 
\cite{Taheriyan2013}.
}
\label{FIG:onto}
\end{figure}

In our work we consider that an ontology $\mathcal{O}$ has such basic elements as classes which represent a set of concepts, literal values, individuals which are members of classes and properties~\cite{Spanos:semweb}.
Properties are classified into object properties, which relate two individuals, and datatype properties, which relate indivuduals to literal values.
An example of an ontology is given in Fig.~\ref{FIG:onto}. 
Here, an individual of the class ``Organisation'' can be related to an individual of the class ``Person'' via object properties ``ceo'' or ``worksFor'', and it can have a data property ``name''. 
We also consider a special ``subclass'' (or ``is-a'') type of object properties.
For 
example, ``Cities'' and ``States'' are both ``Places''. 
A subclass inherits all the properties of the parent class.
\npr{check}

A \emph{semantic model} $m$ is a directed graph with two types of nodes: 
\emph{class nodes} and \emph{data nodes}. 
We denote them as $\mathcal{C}_m$ and $\mathcal{D}_m$ respectively.
 We define $\mathcal{N}_m = \mathcal{C}_m \cup 
\mathcal{D}_m$. $ \mathcal{C}_m$ corresponds to classes in the ontology 
$\mathcal{O}$. $\mathcal{D}_m$ corresponds to data 
properties in the ontology. 
The edges in the semantic model correspond to object properties in the ontology, as shown if Fig.~\ref{FIG:onto} and \ref{FIG:sem}.
The semantic model may have several instances of the same ontology class or object property.

\begin{figure}[ht]
\centering
\begin{tikzpicture}
\begin{scope}
	\node[class] (pe) at (3,0)  {\small Person};
	\node[class] (co) at (6,0) {\small Org.};
	\node[class] (ci) at (1,0) {\small City};
	\node[class] (st) at (-1,0) {\small State};
	
	\node[data] (pen) at (2.5,-1) {\scriptsize Person.name};
	\node[data] (peb) at (4.3,-1) {\scriptsize Person.birthDate};
	\node[data] (cin) at (1,-1) {\scriptsize City.name};
	\node[data] (stn) at (-1,-1) {\scriptsize State.name};
	\node[data] (con) at (6,-1) {\scriptsize Org.name};
	
		
	\path[hasaC,->] (pe) edge [bend left= 0] 
	node [midway, above, sloped] {worksFor} (co) ;
	
	
	\path[hasaC,->] (pe) edge [bend left = 0] 
	node [midway, above, sloped] {bornIn} (ci) ;
	
	
	\path[hasaC,->] (ci) edge  []
	node [midway, above, sloped] {state} (st) ;

	

	\path[draw,hasaA,->] (pe) -- (pen);
	\path[draw,hasaA,->] (pe) -- (peb);	
	
	\path[draw,hasaA,->] (co) -- (con);
	
	\path[draw,hasaA,->] (ci) -- (cin);
	
	\path[draw,hasaA,->] (st) -- (stn);
\end{scope}
\begin{scope}[yshift=-60]
	\node[class] (pl) at (-1,0)  {\small City};
	\node[class] (pe) at (3,0)  {\small Person};
	\node[class] (co) at (1,0) {\small Org.};
	\node[class] (ev) at (6,0) {\small Event};
	
	\node[data] (pen) at (2.5,-1) {\scriptsize Person.name};
	\node[data] (evs) at (4.2,-1) {\scriptsize Event.startDate};
	\node[data] (eve) at (6,-1) {\scriptsize Event.endDate};
	\node[data] (con) at (1,-1) {\scriptsize Org.name};
	\node[data] (pln) at (-1,-1) {\scriptsize City.name};
	
		
	\path[hasaC,->] (co) edge [bend left= 0] 
	node [midway, above, sloped] {ceo} (pe) ;
	
	
	\path[hasaC,->] (ev) edge [bend left = 0] 
	node [midway, above, sloped] {organizer} (pe) ;
	
	\path[hasaC,->] (co) edge [bend left = -10] 
	node [midway, above, sloped] {location} (pl) ;



	\path[draw,hasaA,->] (pl) -- (pln);	

	\path[draw,hasaA,->] (pe) -- (pen);
	
	\path[draw,hasaA,->] (co) -- (con);
	
	\path[draw,hasaA,->] (ev) -- (evs);
	\path[draw,hasaA,->] (ev) -- (eve);
	
\end{scope}
\end{tikzpicture}
\caption{Examples of two semantic models (`\tikz{ \node[class] () at (0,0)  
{};}' are class nodes, and `\tikz{ \node[data] () at (0,0)  {};}' are data 
nodes).}
\label{FIG:sem}
\end{figure}

In our setting we work with relational sources.
Hence, a \emph{data source} $s$ is a $n$-ary relation with a set of attributes 
$\mathcal{A}_s = (a_1,...,a_n)$.
We want to map them to the target ontology $\mathcal{O}$.

Following the traditional data integration framework~\cite{doan2012principles}, we decompose the problem into two parts: schema matching and schema mapping.
Schema matching part, which we refer to as \emph{semantic labeling}, finds correspondences between attributes from data sources and data nodes of the target ontology.
In the schema mapping part we want to generate the semantic models of data sources by identifying the connecting paths for the matched data nodes.

An \emph{attribute mapping} function $\phi : \mathcal{A}_s \mapsto 
\mathcal{D}_m$ is a function which maps the attributes of the source $s$ into the nodes of the semantic model $m$. 
It can be a partial mapping, meaning that only some of the attributes
are connected to the nodes of $m$.
The attribute mapping function addresses the first part of the problem (semantic labeling).

We define a \emph{source description} as a triple $\delta = (s, m, \phi)$ where $s$ is a source, $m$ is a semantic model, and $\phi$ is an attribute mapping.
Our problem can be stated now the following way. We have an ontology 
$\mathcal{O}$ and a set of source descriptions $S_T = \{(s_1, m_1, \phi_1),..., 
(s_l, m_l, \phi_l)\}$.
Given a new source $s^\star$, we want to build a semantic model $m^\star$ and an attribute mapping function $\phi^\star$ such that 
$\delta^\star = (s^\star,m^\star,\phi^\star)$ is an \emph{appropriate} source description. 
We use the term ``appropriate'' since there might be many such triples which are well-formed source descriptions, 
but only one or a few will capture the intended meaning of the source. 
Our goal is to automatically build $\delta^\star$ such that it maximizes the \emph{precision} and \emph{recall} between the semantic model 
$m^\star$ and the semantic model $m^\dag$ that the user considers correct. \npr{definitions for precision and recall}


\section{ML for Training on Source Descriptions \label{SEC:ML}\ddg{Better title 
than this 
please...}}


\subsection{Semantic Labeling}
The semantic types $\mathcal{L_O} = \{l_1, l_2, ..., l_p\}$ of an ontology 
correspond to all pairs $(c,d)$, where $c$ is a Class in $\mathcal{O}$, and $d$ 
is a data property of that class (including inherited properties). 
For example, from the ontology in Fig. \ref{FIG:onto}, we would get types such 
as 
(City,name) and (State,name).

The first step to model the semantics of a new source $s^\star$ is to recognize the semantic types present in the source. 
We call this step \emph{semantic labeling}, which assigns a confidence value to a match of an attribute from $s^\star$ to a type $l \in 
\mathcal{L_O}$.
Typically semantic labeling techniques encounter several problems.
Firstly, there can be naming conflicts~\cite{Pinkel:rodi}, including those cases where users represent the same data in different ways.
Secondly, semantically different attributes might have syntactically similar content, for example, startDate versus endDate for the Event class.
Thirdly, a considerable number of attributes which do not have any corresponding property in the ontology, either by accident or on purpose.
%\ddg{CHECK!}

We formulate the problem of semantic labeling as a multi-class classification
problem.
The known source descriptions $S_T$ provide us the training sample.
We compute a feature vector for each attribute in a data source \ddg{Which features?} and associate the known semantic type with the corresponding feature vector.
The feature vector includes characteristics of the attribute such as a number of whitespaces and other special characters, statistics of values in the column (e.g, mean/ max/ min string length and numeric statistics) and many more.
One of the important features characterising information content of an attribute is Shannon's entropy of the attribute's concatenated rows.
Shannon's entropy (or information entropy~\cite{Manning:Introduction}) of a string $X$ is defined as
$H(X) = -\sum_{i}{p_i \log_{2}p_i},$ where $p_i$ is the probability of a character, whose index in character vocabulary is $i$, to appear in $X$, and the summation ranges over all
characters in the vocabulary of all possible characters.
To evaluate $p_i$ in Shannon's entropy, we evaluate normalized character frequency distribution \emph{chardist} of an attribute, as character counts in concatenated rows of the attribute, normalized by the total length of the concatenated rows.
The vocabulary of all characters consists of 100 printable characters (including $\backslash$n).
Finally, we add the 100-dimensional vector of $p_i$ to the attribute feature vector.
We also compute a set of features based on similarity metrics inspired by state-of-the-art works~\cite{Pham:semantic} or~\cite{Ritze:matching}.
Among others, we compute mean cosine similarity for character distributions of attribute values and string similarity metrics for attribute names.
%To extract features from attribute names, we compute string similarity metrics: minimum edit distance, two WordNet based similarity measures such as JCN~\cite{Jiang:Semantic} and LIN ~\cite{Lin:Information}, and $k$-nearest neighbors using Needle-Wunsch distance~\cite{Needleman:General}.
%The minimum edit distance between two strings $s_1$ and $s_2$ is the minimum number of edit operations, such as insertion, deletion, substitution, which are required to transform one string into another~\cite{Manning:Introduction}.
%We compute the similarity between attribute name and all class instances in the training data.
%The number of thus extracted features depends on the number of semantic labels in the training data.
We train a random forest on the obtained sample. 

In such way, we learn the mapping $\psi : \mathcal{A}_s \times \mathcal{L_O} 
\mapsto [0, 1]$,
where $\psi(a_i,l_j)$ indicates the confidence of the attribute $a_i$ to be 
mapped to the semantic type $l_j$.

\ddg{IMPORTANT: Do we keep all of them, or only the top $k$ with most 
confidence? If so, 
what is $k$?}
\npr{We keep all, that is the crucial difference from Karma which does some voodoo heuristic filtering}


\subsection{Alignment Graph}

To provide an integrated view over the known source descriptions $S_T$, we 
need to align their semantic models as well as all considered semantic 
types. 
This is achieved by constructing an \emph{alignment graph}. 

The alignment graph is a directed weighted graph $\mathcal{G_O} = 
(\mathcal{V_O},\mathcal{E_O})$ built on top 
of the known semantic models and expanded using the semantic types 
$\mathcal{L_O}$ and the ontology $\mathcal{O}$. 
Similar to a semantic 
model, $\mathcal{G_O}$ contains both class and data nodes.
The links correspond 
to properties in  $\mathcal{O}$ and are weighted \cite{taheriyan2016learning}.

The algorithm for the construction of the alignment graph $\mathcal{G_O}$ follows the ideas of~\cite{taheriyan2016learning}.
Briefly, the algorithm has three parts:
\begin{enumerate}
\item Adding the known semantic models.
\item Adding the semantic types learned for the target source. \ddg{TODO: see 
Important note above}
\item Expanding the graph using the domain ontology $\mathcal{O}$.
\end{enumerate}

Note how the alignment graph contains data nodes that correspond to at least 
some of the semantic types. 
For instance, it could contain two nodes $City.name$ and $State.name$ rather than just one node $name$ connected to two 
nodes $City$ and $State$. 
We say these nodes are \emph{induced} into the 
alignment graph by the semantic types.
We denote them as $\mathcal{D_{G_O}}$ and call them the \emph{data nodes} of the alignment graph.

The graph is weighted by a function $w_\mathcal{O} : \mathcal{E_O} \mapsto 
\mathbb{R}$ in 
such a way that edges which are present in
the known semantic models have lower weights than those 
which are inferred from the ontology.
As we will see in the next section, this makes edges present in semantic models more attractive. \ddg{How exactly are 
they weighted?}

An example alignment graph is illustrated in Fig.~\ref{FIG:ali}. 
Bigger examples can be found in \cite{Taheriyan2013}. 
Black links correspond to the links which are supported by the known semantic models. 
Blue and orange links are inferred from the ontology $\mathcal{O}$ (the orange ones correspond to the ones added to connect Classes of the ontology that never appeared in the semantic models) and can be assigned the 
maximum weight $w_max$ \ddg{where does this weight come from?} .


\begin{figure}[ht]
\centering
\begin{tikzpicture}

	\node[class] (pe1) at (3,0)  {\small Person1};
	\node[class] (co1) at (6,0) {\small Org.1};
	\node[class] (ci1) at (1,0) {\small City1};
	\node[class] (st1) at (-1,0) {\small State};
	
	\node[data] (pen) at (2.3,1) {\scriptsize Person1.name};
	\node[data] (peb) at (4.2,1) {\scriptsize Person1.birthDate};
	\node[data] (cin) at (0.7,1) {\scriptsize City1.name};
	\node[data] (stn) at (-1,1) {\scriptsize State.name};
	\node[data] (con) at (6,1) {\scriptsize Org1.name};
	
		
	\path[hasaC,->] (pe1) edge [bend left= 0] 
	node [midway, above, sloped] {worksFor} (co1) ;
	
	
	\path[hasaC,->] (pe1) edge [bend left = 0] 
	node [midway, above, sloped] {bornIn} (ci1) ;
	
	
	\path[hasaC,->] (ci1) edge  []
	node [midway, above, sloped] {state} (st1) ;

	

	\path[draw,hasaA,->] (pe1) -- (pen);
	\path[draw,hasaA,->] (pe1) -- (peb);	
	
	\path[draw,hasaA,->] (co1) -- (con);
	
	\path[draw,hasaA,->] (ci1) -- (cin);
	
	\path[draw,hasaA,->] (st1) -- (stn);


% % % CC2
\def\ysh{-2.5};

	\node[class] (pl2) at (-1,0+\ysh)  {\small City2};
	\node[class] (pe2) at (3,0+\ysh)  {\small Person2};
	\node[class] (co2) at (1,0+\ysh) {\small Org.2};
	\node[class] (ev2) at (6,0+\ysh) {\small Event};
	
	\node[data] (pen) at (2.3,-1+\ysh) {\scriptsize Person2.name};
	\node[data] (evs) at (4.2,-1+\ysh) {\scriptsize Event.startDate};
	\node[data] (eve) at (6,-1+\ysh) {\scriptsize Event.endDate};
	\node[data] (con) at (0.7,-1+\ysh) {\scriptsize Org2.name};
	\node[data] (pln) at (-1,-1+\ysh) {\scriptsize City2.name};
	
		
	\path[hasaC,->] (co2) edge [bend left= 0] 
	node [midway, above, sloped] {ceo} (pe2) ;
	
	
	\path[hasaC,->] (ev2) edge [bend left = 0] 
	node [midway, above, sloped] {organizer} (pe2) ;
	
	\path[hasaC,->] (co2) edge [bend left = -10] 
	node [midway, above, sloped] {location} (pl2) ;



	\path[draw,hasaA,->] (pl2) -- (pln);	

	\path[draw,hasaA,->] (pe2) -- (pen);
	
	\path[draw,hasaA,->] (co2) -- (con);
	
	\path[draw,hasaA,->] (ev2) -- (evs);
	\path[draw,hasaA,->] (ev2) -- (eve);
	

% % % Ontology

	\path[draw,hasaC,->,blue!70] (co2)  edge [bend left = -5] (pe1);
	\path[draw,hasaC,->,blue!70] (pe1)  edge [bend left = -5] (co2);
	
	\path[draw,hasaC,->,blue!70] (co1)  edge [bend left = -5] (pe2);
	\path[draw,hasaC,->,blue!70] (pe2)  edge [bend left = -5] (co1);

	\path[draw,hasaC,->,blue!70] (pl2) -- (st1);
	
	\path[draw,hasaC,->,blue!70] (ev2) -- (pe1);
	
	
	\node[class,fill=orange!30!white] (PL) at (3,\ysh/2)  {\small Place};
	
	\path[draw,hasaC,->,orange!30!white] (pe1) edge[bend left=10] (PL);
	\path[draw,hasaC,->,orange!30!white] (pe1) edge[bend left=-10] (PL);
	
	\path[draw,hasaC,->,orange!30!white] (pe2) edge[bend left=10] (PL);
	\path[draw,hasaC,->,orange!30!white] (pe2) edge[bend left=-10] (PL);
	
	\path[draw,hasaC,->,orange!30!white] (co1) edge[bend left=0] (PL);
	\path[draw,hasaC,->,orange!30!white] (co2) edge[out=45,in=225] (PL);

	\path[draw,hasaC,->,orange!30!white] (ev2) edge[out=90,in=0] (PL);
	
	\path[draw,isa,->,orange!30!white] (ci1) edge[out=-45,in=120] (PL);
	\path[draw,isa,->,orange!30!white] (pl2) edge[out=90,in=180] (PL);
	\path[draw,isa,->,orange!30!white] (st1) edge[out=-45,in=150] (PL);

\end{tikzpicture}
\caption{Example of alignment graph (`\tikz{ \node[class] () at (0,0)  
{};}' and `\tikz{ \node[class,fill=orange!30!white] () at (0,0)  
{};}' are class nodes, and `\tikz{ \node[data] () at (0,0)  {};}' are data 
nodes). We omit weights for clarity.}
\label{FIG:ali}
\end{figure}


\subsection{Frequent Graph Pattern Mining \label{SSEC:pattern-mining}}

Certain patterns of connections can be prevalent in the domain.
For example, in Fig.~\ref{FIG:sem} both semantic models have class nodes ``City'', ``Organization'' and ``Person''.
According to the ontology in Fig.~\ref{FIG:onto} there are multiple ways to connect these nodes.
However, if we know that the ``Person'' works for the ``Organization'', then based on the known semantic models ``City'' is more likely to be the birth place of the ``Person'' rather than the location of the ``Organization''.
To increase the coherence of the generated semantic models, we would like to discover such patterns of connections.

%As an extension to the problem, we consider using pattern mining techniques in order to identify patterns in the training set of semantic model that repeat themselves often. 
%The hope is that with such information we can encourage the semantic model $m^\star$ for the new source to use groups of edges that                                       appeared often together in training semantic models.

\npr{reformulate for typed directed multigraphs and example based on Fig3}
In our context, patterns are typed directed graphs.
We mine these patterns from the set of semantic models in the training set $S_T$.
This is known as Transactional Frequent Graph Pattern Mining, which contains the subgraph 
isomorphism, known to be NP-complete.
The frequency of a pattern is an anti-monotonous measure, meaning that bigger patterns will have lower supports than their subgraphs.
We solve this pattern mining task with the tool DIMSpan \cite{petermann2017dimspan} which adapts gSpan~\cite{yan2002gspan} pruning techniques to the typed graphs and uses Apache Flink for scalability.  
We obtain patterns of size upto 6 in under 4 minutes for the biggest instances in our evaluation framework. 
\npr{Elaborate more, karma's approach for pattern mining took 1 hour, maybe cite my work on how databases perform for graph pattern matching. Should it be better in related work?}


%Let $G = (V_G,E_G,\lambda_G)$ and $P = (V_P,E_P, \lambda_P)$ be two graphs 
%where $\lambda_G$ (resp. $\lambda_P$) is a \emph{labeling function} that maps 
%nodes/edges of $G$ (resp. $P$) into a set of labels (e.g. natural numbers).
%An \emph{embedding} of $P$ into $G$ is an injective function $f : V_G \mapsto 
%V_P$ such that for all $x,y \in V_P$:
%\begin{enumerate}
%	\item $\{x,y\} \in E_P \implies \{f(x),f{y}\} \in E_G$.
%	\item $\lambda_P(x) = \lambda_G(f(x))$
%	\item $\lambda_P(\{x,y\}) = \lambda_G(\{f(x),f(y)\})$
%\end{enumerate} 
%That is, if an edge exists in $P$, it must also exist in $G$ (but not 
%vice-versa); and the labelling functions of both graphs must match after 
%applying the embedding function.

%Our goal is to take a set of graphs (the semantic models from the training set 
%$S_T$) and find patterns that appear often across that set of graphs. 
%This is 
%known as the Frequent Graph Pattern Mining, which contains the subgraph 
%isomorphism, known to be NP-complete.  
%We solve this task with the tool DIMSpan \cite{petermann2017dimspan} which adapts gSpan~\cite{yan2002gspan} pruning techniques to the typed graphs and uses Apache Flink for scalability. 
%\ddg{CHECK! How do they solve an NP-complete problem??}
%\npr{Im not sure what to say here: there is just no guarantee how long it will take for the whole thing to run, except there is a threshold on how frequent they have to be; they use gSpan procedure to prune patterns and a variant of Ulmans algorithm for graph pattern matching}
% 
%This tool provides us with a list of patterns that are frequent, as well as 
%their support. 
%The \emph{support} of a pattern is an anti-monotonous measure of frequency. 
%Thus, the higher the support, the more often the pattern appears. 
%This typically means that big patterns have low support.
 

\section{Steiner Tree Formulation \label{SEC:STP}}

Given a graph $G =
(V, E)$ and a subset of its nodes $T \subseteq V$ , called \emph{terminals}, a 
Steiner Tree $G_s = (V_s, E_s )$ is a tree such that $T \subseteq V_s \subseteq 
V$ and $E_s \subseteq E$. In other words, $G_s$ spans all the nodes in $T$ and 
may include additional nodes from $V$, in particular to ensure the 
connectedness of the constructed tree. The Steiner Tree Problem 
(STP) is stated as follows: given $G$ and a weight function $w_f : E 
\mapsto \mathbb{R}$, find the Steiner Tree that minimizes the sum of the 
weights of the edges in $E_s$ given by $w_f$. This was proven to be NP-hard 
by Karp \cite{Karp1972}.

To formulate the \relonto{} schema mapping problem as a STP for a new source 
$s^\star$, we construct the 
\emph{integration graph} $~\mathcal{I}_\mathcal{O}^{s^\star} = 
(\mathcal{V}_\mathcal{O}^{s^\star},\mathcal{E}_\mathcal{O}^{s^\star})$, with 
nodes $\mathcal{V}_\mathcal{O}^{s^\star} = \mathcal{V_O} \cup 
\mathcal{A}_{s^\star}$, 
edges $\mathcal{E}_\mathcal{O}^{s^\star}$.

The set of edges $\mathcal{E}_\mathcal{O}^{s^\star}$ is constructed by using 
all the edges in the alignment 
graph, and edges connecting each attributes of $s^\star$ to the nodes in the 
alignment graph \emph{induced} by the semantic types (i.e. the set of nodes in 
$\mathcal{D_{G_O}}$). We call this last set 
of edges $\mathcal{M}_\mathcal{O}^{s^\star}$ (for ``matches''). Thus, 
$\mathcal{E}_\mathcal{O}^{s^\star} = 
\mathcal{E_O} \cup \mathcal{M}_\mathcal{O}^{s^\star}$.

We associate a weighting function  $w_\mathcal{I} : E \mapsto \mathbb{R}^+$ to 
the integration graph. For an edge $e \in \mathcal{E_O}$, $w_\mathcal{I}(e) = 
w_\mathcal{O}(e)$. For an edge $e 
\in \mathcal{M}_\mathcal{O}^{s^\star}$ connecting attribute $a_i$ to the node 
$l_j$ induced by the semantic model, $w_\mathcal{I}(e) = - 
ln(\psi(a_i,l_i))$. \ddg{CHECK!}

An example of integration graph can be found in Fig. \ref{FIG:inte}.




\begin{figure}[ht]
\centering
\begin{tikzpicture}
	\node[class, rectangle, rounded corners] (CLASS) at (0,0) { \small{Class 
	Nodes of Alignment Graph}};
	
	\node[data] (stn1) at (-3.9,-1) {\scriptsize S.n};
	\node[data] (cin1) at (-3.1,-1) {\scriptsize C1.n};
	\node[data] (pen1) at (-2.3,-1) {\scriptsize P1.n};
	\node[data] (peb1) at (-1.5,-1) {\scriptsize P1.b};
	\node[data] (con1) at (-0.7,-1) {\scriptsize O1.n};
	
	\path[draw,hasaA] (CLASS) edge[out=180,in=90] (stn1);
	\path[draw,hasaA] (CLASS) edge[out=190,in=90] (cin1);	
	\path[draw,hasaA] (CLASS) edge[out=200,in=90] (pen1);
	\path[draw,hasaA] (CLASS) edge[out=210,in=90] (peb1);	
	\path[draw,hasaA] (CLASS) edge[out=220,in=90] (con1);


% % % CC2
\def\ysh{0};
	
	\node[data] (cin2) at (0.7,-1+\ysh) {\scriptsize C2.n};
	\node[data] (con2) at (1.5,-1+\ysh) {\scriptsize O2.n};
	\node[data] (pen2) at (2.3,-1+\ysh) {\scriptsize P2.n};
	\node[data] (evs2) at (3.1,-1+\ysh) {\scriptsize E.s};
	\node[data] (eve2) at (3.9,-1+\ysh) {\scriptsize E.e};
	
	\path[draw,hasaA] (CLASS) edge[out=320,in=90] (cin2);	
	\path[draw,hasaA] (CLASS) edge[out=330,in=90] (con2);
	\path[draw,hasaA] (CLASS) edge[out=340,in=90] (pen2);
	\path[draw,hasaA] (CLASS) edge[out=350,in=90] (evs2);
	\path[draw,hasaA] (CLASS) edge[out=360,in=90] (eve2);
	
\node[rectangle, rounded corners,very thick,draw, dashed, 
brown!40!red!40!white,minimum 
height=18, minimum 
width=220] 
(source) at 
(0,-3) 
{};
\node[brown!40!red!40!white] 
(source) at 
(-4.1,-3) 
{$s^\star$:};
	\node[att] (a1) at (-3,-3) {\small Surame};
	\node[att] (a2) at (-1,-3) {\small Workplace};
	\node[att] (a3) at (1,-3) {\small Date};
	\node[att] (a4) at (3,-3) {\small Location};

	\path[draw] (a1) -- (stn1);
	\path[draw] (a1) -- (cin1);
	\path[draw] (a1) -- (pen1);
	\path[draw] (a1) -- (cin2);
	\path[draw] (a1) -- (pen2);
	
	\path[draw] (a2) -- (cin1);
	\path[draw] (a2) -- (con1);
	\path[draw] (a2) -- (con2);

	\path[draw] (a3) -- (peb1);
	\path[draw] (a3) -- (evs2);
	\path[draw] (a3) -- (eve2);

	\path[draw] (a4) -- (stn1);
	\path[draw] (a4) -- (cin1);
	\path[draw] (a4) -- (con1);
	\path[draw] (a4) -- (cin2);
	\path[draw] (a4) -- (con2);
\end{tikzpicture}
\caption{Example of integration graph. (`\tikz{ \node[att] () at (0,0)  
{};}' are attribute nodes). We omit weights for clarity. Data node labels are 
abbreviated but 
correspond to the ones shown in Fig \ref{FIG:ali}.}
\label{FIG:inte}
\end{figure}

Note that, although the alignment graph is directed, the semantic models are 
not necessarily rooted directed trees (e.g. Fig. \ref{FIG:sem}), therefore the 
direction of the edges is ignored for the STP model (and are all treated as 
undirected edges). 

The goal is to build a subgraph $T^\star= (V^\star, E^\star)$ 
of the integration graph 
$\mathcal{I}_\mathcal{O}^{s^\star}$ for the new source $s^\star$. The solution 
$T^\star$ will 
be used to build the source description $\delta^\star = (s^\star, m^\star, 
\phi^\star)$. 
In particular, $(\mathcal{V_O} \cap V^\star,\mathcal{E_O} \cap E^\star)$ 
corresponds to the semantic model, and 
$(\mathcal{A}_{s^\star},\mathcal{M}_\mathcal{O}^{s^\star} \cap E^\star)$ 
corresponds to 
the attribute mapping function.

The solution $T^\star$ must satisfy the following constraints:
\begin{enumerate}
	\item $T^\star$ must be a subgraph of $\mathcal{I}_\mathcal{O}^{s^\star}$
	\item $T^\star$ must be a tree (connected acyclic graph)
	\item $\forall a \in \mathcal{A}_{s^\star}, a\in V^\star$
	\item $\forall a \in \mathcal{A}_{s^\star}, degree(a) = 1$
	%\item $\forall n \in \mathcal{D_{G_O}}, degree(a) \in 
	%\{0,2\}$
	\item $\forall n \in \mathcal{D_{G_O}} \cap V^\star, 
	degree(a) = 2$
\end{enumerate}

It is therefore natural to model this a STP with side constraints, since the 2 
first requirements imply that $T^\star$ is a Steiner Tree of the integration 
graph. By designing the weighting function $w_\mathcal{I}$ through ML 
techniques, as shown in Section \ref{SEC:ML}, 
our hope is that the minimum weight Steiner Tree is a valid semantic model for 
the new source.


\subsection{Using Patterns}

As explained in Subsection \ref{SSEC:pattern-mining}, we also tried to use 
frequently appearing patterns in order to incentivise the solution tree 
$T^\star$ to contain subgraphs of the alignment graph that have been frequently 
seen in the training set.

To do this, we use the support of each of the obtained patterns as a prize. If 
the tree contains a pattern, then its weight is automatically reduced by a the 
value of the support of that pattern. We will see in the next section how this 
information is integrated in the model.

\subsection{Unmatched Attributes}
It is common that the data sources to be integrated will have columns that 
simply can't be matched to the ontology.
This can happen when a column of a source table contains some information that 
is uninteresting to the user, or because the ontology has not been properly 
designed. 
Examples of these situations can be found in domain specific data 
\cite{Pham:semantic} or HTML tables \cite{Ritze:matching}.
In current systems, these columns are removed in a reprocess that requires extra time and effort as this is typically done manually in the real world.

For this reason, we add two artificial Class nodes to the integration graph:  
\emph{unknown} and \emph{root}. 
The latter will be connected to every other Class node in 
$\mathcal{V}_\mathcal{O}^{s^\star}$, including \emph{unknown}.
We also add a set $U = \{unk_1,...,unk_{|\mathcal{A}_{s^\star}|}\}$ of 
$|\mathcal{A}_{s^\star}|$ data 
nodes to the integration graph each connected to exactly one node in 
$\mathcal{A}_{s^\star}$ and to the \emph{unknown} Class node.  

If an attribute $a$ is matched to $unk_a$, then $unk_a$ will be linked to Class 
node \emph{unknown}. 
The rest of the attributes can then be matched normally 
and build  a semantic model as usual. 
Then, to maintain connectedness of the 
Steiner tree, the \emph{unknown} node and one of the selected Class nodes will 
both be connected to the \emph{root} node. 
Note that if all attributes find a 
match, then both the \emph{unknown} and \emph{root} won't be selected in the 
Steiner tree and the normal behavior will take place.
\ddg{Explain the weights of the edges introduced by the unknown nodes}




\section{Modeling as a Constraint Optimization Problem \label{SEC:CP}}

\subsection{Definitions}
A Constraint Satisfaction Problem (CSP) is a tuple $P = (\boldsymbol{v},D,C)$ 
where $\boldsymbol{v}$ is a 
set of \emph{variables}, $D$ is a set of unary constraints over 
$\boldsymbol{v}$ specifying 
the \emph{domain} of these variables, $C$ is a set of $n$-ary 
\emph{constraints} over variables $\boldsymbol{v}$.
A valuation $\theta(\boldsymbol{v})$ is a mapping from the set of variables to 
values in $D$. 
If there exist a valuation $\theta^\star$ such that all 
variables map 
to exactly one value, and all the constraints in $D\cup C$ are satisfied by the 
valuation, then $\theta^\star$ is a \emph{solution} to $P$.

A Constraint Optimization Problem (COP) is a CSP with an additional 
\emph{objective function} $o : \boldsymbol{v} \mapsto \mathbb{R}$ and a 
\emph{sign} which is either \verb|minimize| or \verb|maximize|. 

A typical example of COP is the Traveling Salesman Problem, where we need to 
find a route that visits all cities in a region exactly one and is of minimal 
length.

\subsection{Constraint Programming}
Constraint Programming (CP) allows the user to model a CSP or COP and give it 
to a 
solver that will find a solution to the CSP, or will report unsatisfiability if 
no solution exists. In the case of COPs, the solver will try to optimize 
the objective function and prove optimality as well.

Briefly, the way a CP solver works is by assigning a value to each variable of 
$\boldsymbol{v}$ from $D$ in turn. At each iteration it will check whether any 
constraint in $C$ is violated, in which case it will backtrack to change it's 
last decision. The choice of the order of the variables to be assigned, and the 
choice of the value to be assigned to each variable is called the \emph{search 
strategy}.

Since only using a backtracking algorithm would have a prohibitive cost, CP 
uses a combination of search and \emph{propagation}. The latter is achieved by 
\emph{propagating} the last decision made via specialized algorithms called 
\emph{propagators}. A propagator is a function $p : (v, D_v) \mapsto D_v'$ that 
takes a subset of the variables of the problem $v \subseteq \boldsymbol{v}$ and 
the domain of those variables $D_v$ and returns a new domain for these 
variables 
such that $D_v' \sqsubseteq D$. That is, a propagator removes values form the 
domains of variables (when possible). For a propagator to be correct, it must 
not remove a value of the domain of a variable if such value could participate 
in a solution given the decisions already made.

\emph{Global constraints} are higher order constraints that enforce a 
complicated 
constraint over a set of variables. Typical examples of this is enforcing that 
a set of variables take different values, or that they describe a path a in a 
graph. Although it is possible to express these constraints with a conjunction 
of simple constraints, it is often the case that specific algorithms for these 
constraints perform substantially better than a decomposition approach (e.g. 
\cite{regin1994filtering}). A wide 
list of these global constraints can be found in \cite{beldiceanu2012global}.

\subsubsection{Example} Consider the toy problem $P$ over variables $a$ and $b$ 
such that $a \in \{2,3,4\}$, $b \in \{1,2,3\}$. Let $C = \{a + 2b \leq 4, a 
\neq b\}$ be the constraints. If the search step decides that $a = 
2$, then $(i)$ $a \neq b \Rightarrow b \in \{1,3\}$ and $(ii)$ $a + 2b \leq 4  
\Rightarrow b \in \{1\}$. Thus we automatically know that $b = 1$ without never 
trying any other of its original possible values. $\square$


\subsection{\relonto{} in Constraint Programming}
In order to model this problem we used the \minizinc{} language 
\cite{minizinc}, and the 
\chuffed{} solver \cite{chu2011improving} because it has a global constraint 
implemented for Steiner 
Tree Problems \cite{deuna2016steiner}. 

Because attributes must be connected to exactly one node of the alignment 
graph, and that node will be in $\mathcal{D_{G_O}} \cap V^\star$ 
then the part of the problem between attribute nodes and the alignment graph is 
actually a matching problem. Each attribute must match exactly to one node of 
$\mathcal{D_{G_O}}$. Note that not all nodes in $\mathcal{D_{G_O}}$ must match 
to an attribute, as not all of them are part of $T^\star$.

Because there are global constraints in CP specialized in matching 
\cite{regin1994filtering}, we split the problem into two parts: the 
\verb|steiner_tree| global constraint will only deal with the part of the 
integration graph that corresponds to the alignment graph, and the 
\verb|alldifferent| global constraint will deal with he matching part of the 
problem.

We use the following variables to represent the tree $T^\star$: Boolean 
variables $c_n,\forall n \in 
\mathcal{V_O}$, $c_e, \forall e \in	\mathcal{E_O}$ and an array of variables 
$match$ indexed by the set of attributes of $s^\star$. The combination of these 
sets fo variables define the value of $T^\star$: $c_n = \mathit{true}$ means 
that $n \in V^\star$, $c_e = \mathit{true}$ means that $e \in E^\star$ and 
$match[a] = d$ (for $a \in \mathcal{A}_{s^\star}$ and $d \in 
\mathcal{D_{G_O}}$) means that the edge $(a,d) \in 
\mathcal{M}_\mathcal{O}^{s^\star}$ is part of $T^\star$.

Additionally, for a given set of patterns $\mathcal{P}$ with a support function 
$w_\mathcal{P} : \mathcal{P} \mapsto \mathbb{R}$, we have a set of Boolean 
variables 
$c_p, \forall p \in \mathcal{P}$ that tells us whether a pattern $p$ appears in 
$T^\star$ or not.
The model is presented below.

\begin{flalign}
	& \text{Minimize~~} w_{STP} + w_{ADIFF} - w_{PAT}
	%\sum_{e \in \mathcal{E}_\mathcal{O}}c_e * 
	%w_\mathcal{I}(e) + \sum_{e \in \mathcal{M}_\mathcal{O}^{s^\star}} c_e * 
    %		w_\mathcal{I}(e)
	\label{EQ:obj}&&\\
	&\text{such that~~}  \nonumber&& \\
	& \textit{steiner}(\{c_n| n \in \mathcal{V_O}\},\{c_e| e \in 
	\mathcal{E_O}\},\mathcal{G_O},w_\mathcal{O},w_\mathit{STP})  \label{EQ:stp} 
	&&\\
	&\forall d \in \mathcal{D_{G_O}}, degree(d) \leq 1 \label{EQ:deg1}&&\\
	&\forall d \in \mathcal{D_{G_O}}, c_d \Leftrightarrow degree(d) = 1 
	\label{EQ:deg2}&&\\
	&\forall a \in \mathcal{A}_{s^\star}, match[a] \in \{ d | (a,d)\in 
	\mathcal{M}_\mathcal{O}^{s^\star} \} \label{EQ:matchdom}&&\\
	& \textit{alldifferent}(match) \label{EQ:alld}&& \\
	& \forall a \in \mathcal{A}_{s^\star}, c_{match[a]} = \mathit{true} 
	\label{EQ:map}&&\\
	& w_{\mathit{ADIFF}} = \sum_{(a,d) \in \mathcal{M}_\mathcal{O}^{s^\star}} 
	w_\mathcal{I}(~(a,d)~) * \llbracket match[a] = d\rrbracket 
	\label{EQ:matchcost}  &&\\
	& \forall p \in \mathcal{P}, \big(\forall e\in edges(p), c_e = 
	\mathit{true} \big) \Leftrightarrow c_p \label{EQ:patt}&&\\
	& w_{PAT} = \sum_{p\in\mathcal{P}} w_\mathcal{P}(p)* c_p 
	\label{EQ:pcost} &&\\
	& c_{unknown} \Rightarrow \big( c_{root}  \land 
	c_{(unknown,root)} \big) \label{EQ:unk}
\end{flalign}

Eq. \ref{EQ:obj} is the objective function: we are minimizing the cost 
of $T^\star$ while collecting prizes for each pattern we use. Eq. \ref{EQ:stp} 
enforces that the solution 
$T^\star$ is indeed a tree defined by the $c_n$ and $c_e$ variables, subgraph 
of the alignment graph 
and of total weight $w_{STP}$. Equations \ref{EQ:deg1} and \ref{EQ:deg2} ensure 
that if a data node of the alignment graph is selected, then at most one edge 
reaches it (from the side of the alignment graph) and otherwise it is 
disconnected. Eq. \ref{EQ:matchdom} ensures that the domain of each variable in 
the array $match$ corresponds to a subset of data nodes of the alignment graph 
for which there is an edge connecting to the attribute at hand. Eq. 
\ref{EQ:alld} ensure that each attribute is mapped to exactly one data node of 
the alignment graph. Equations \ref{EQ:matchdom} and \ref{EQ:alld} ensure that 
there is exactly one data node matched to an attribute, which has to be one of 
the ones for which an edge existed. Eq. \ref{EQ:map} ensures that 
if a data node of the alignment graph has been mapped to some attribute, then 
that data node must be in the solution tree, and vice-versa. Eq. 
\ref{EQ:matchcost} computes the cost $w_{ADIFF}$ of the matches.
Eq. \ref{EQ:patt} indicated that a pattern is used if and only if all its edges 
are selected in the tree. Eq. \ref{EQ:pcost} computes the prizes collected by using patterns.
Eq. \ref{EQ:unk} ensures that if the \emph{unknown} class node is used, then it 
is connected to \emph{root}.
Notice how there is no further requirement for unmatched attributes, as the 
$unk_i$ data nodes behave like normal data nodes, and the connectedness 
requirement will make sure that \emph{root} is connected to the rest of the 
tree (i.e. the semantic model).

Note how this CP model is easily adaptable to more classic settings where no 
patterns are used (by dropping Eqs. \ref{EQ:patt} and \ref{EQ:pcost}), or where 
the \emph{unknown} nodes are used (by dropping \ref{EQ:unk}).
\section{Results \label{SEC:Res}}

\subsection{Experimental Setup}
\ddg{TODO}

% datasets for evaluation
We run experiments on two domains: museum and soccer (see Fig.~\ref{tab:data} for statistics).
The museum dataset~\cite{taheriyan2016learning} contains 29 sources which are mapped to the EDM domain ontology.
The soccer dataset~\cite{Pham:semantic} is much smaller with only 12 data sources, and its domain ontology is an extension of the schema.org ontology.

\begin{table}[ht]\small
  \centering
  \caption{Description of data sources.}\label{tab:data}
		\begin{tabular}{ccccc}
		\hline
		\multirow{2}{*}{\textbf{Domain}} & \# data & \# semantic & \# & \# unknown\\
		 & sources & labels & attributes & attributes\\
		\hline
		museum & 29 & 20 & 443 & 159  \\
		soccer & 12 & 18 & 138 & 42 \\
		\hline
		\end{tabular} 
\end{table}

%\begin{table*}[ht]
%  \centering
%  \caption{Description of data sources.}\label{tab:data}
%		\begin{tabular}{ccccccc} 
%		\hline
%		\multirow{2}{*}{\textbf{Domain}} & \# & \# semantic & \# & \# unknown & avg \# rows & avg \# attributes\\
%		 & sources & labels & attributes & attributes & per source & per source\\
%		\hline
%		museum & 29 & 20 & 443 & 159 & 6978.89 & 15.27 \\
%		soccer & 12 & 18 & 138 & 42 & 2120.16 & 11.5 \\
%		\hline
%		\end{tabular} 
%\end{table*}

% baseline for evaluation
We choose \emph{Karma}~\cite{taheriyan2016learning} as our baseline.
This system also phrases the \relonto{} problem as STP and decomposes it further into two parts.
However, they use heuristic algorithms both for the matching and for the STP parts.
They solve the problems sequentially, i.e., once they produce a set of candidate mappings for attributes into the ontology, they fix this set and move onto the STP part.
Additionally, they do not consider unmatched attributes in the sources.
To ensure that Karma also handles such attributes, we change its semantic labeling model SemanticTyper~\cite{Ramnandan:Assigning} to ours and we add a special \emph{unknown} ontology which gives specification for \emph{root} and \emph{unknown} nodes of the alignment graph.
The first modification also ensures the fairness of evaluation since both Karma and Serene will have the same matches for attributes.

% performance metrics
The performance of these systems is estimated in terms of \emph{precision} and \emph{recall}.
Assuming $m^\star$ is the predicted semantic model and $m^\dag$ is the correct semantic model, then:
$$precision = \frac{|rel(m^\star)\cap rel(m^\dag)|}{|rel(m^\star)|}$$
$$recall = \frac{|rel(m^\star)\cap rel(m^\dag)|}{|rel(m^\dag)|}$$
where $rel(m)$ is the set of triples $(u,e,v)$ with $e$ being an edge from the vertex $u$ to the vertex $v$ in the semantic model $m$.
Since we want to estimate the accuracy of both the matching and STP parts,
we also include triples for attributes and data nodes into the corresponding sets.
Note that unmatched attributes as well as \emph{unknown} and \emph{root} nodes are not part of these sets.
We perform also a modification to the ground truth semantic models:
if the true semantic label of an attribute is not present in any of the previously mapped data sources,
we substitute it with \emph{unknown} and map it to the \emph{Unknown} class node.
In such way we validate how well the systems can detect earlier unseen cases.

% semantic labeling models
To illustrate that our semantic labeling model is better suited for the
matching task, we compare it against the state-of-the-art model \emph{DSL}~\cite{Pham:semantic} which was shown to perform even better than SemanticTyper. 
\npr{not sure whether I should explain how this model works}
We use \emph{mean reciprocal rank} (MRR) to evaluate semantic labeling models.
This measure is useful to estimate how highly the true semantic label is ranked among top $k$ suggestions.
It is calculated the following way:
$$MRR = \frac{1}{n}\sum_{i=1}^{n}{\frac{1}{rank_i}},$$
where $rank_i$ is the rank of the correct semantic label for the attribute $a_i$ among the top $k$ predictions.


% evaluation strategy
We perform an evaluation strategy outlined by~\cite{taheriyan2016learning}.
Let $M_j$ be the set of $j$ known semantic models.
For each data source $s_i$ in the domain we perform experiments $t-1$ times,
where $t$ is the total number of data sources in the domain and each experiment has a different number of known semantic models $M_1, M_2, \ldots, M_{t-1}$.
The case with $M_{t-1}$ known semantic models corresponds to leave-one-out validation strategy. 
For example, in the soccer domain for the source $s_1$ we run experiments 11 times using $M_1=\{m_2\}, M_2=\{m_2, m_3\}, \ldots, M_{11}=\{m_2, m_3, \ldots, m_{12}\}$
We repeat the procedure for other data sources in the domain and then average the results.
Such procedure ensures that each source is at least once in the training as well as testing datasets.


% architecture
We have run all our experiments on a Dell server with 252 GiB of memory, 2 CPUs with 4 cores each, 1 Titan GPU and 1 GeForce 1080 Ti GPU.
\npr{check characteristics, AWS machine is bigger}
In all our experiments we use a timeout threshold of 15s for the chuffed solver.

\subsection{Experimental Results}
\ddg{TODO}

To evaluate our new system \emph{serene}, we show that its semantic labeling model produces more accurate matches for attributes and the CP formulation leads to better semantic models in terms of precision and recall.

We have developed a new approach for semantic labeling which can efficiently handle the \emph{unknown} class.
We demonstrate its efficiency by comparing against the state-of-the-art approach DSL~\cite{Pham:semantic}.
Tab.~\ref{tab:semlab} provides evidence that our new semantic labeling model is better suited for the task when there are unmatched attributes in domains.
DSL uses heuristic measures to capture the similarity of attributes within the same class.
It is clear that we cannot directly speak about similarity for unmatched attributes, since they are rather dissimilar from known semantic types.
Our intution why our approach performs better is that we have encorporated features which are derived directly from attribute values and are not based on the notion of similarity.
\npr{Good enough explanation?}

\begin{table}[t]\small
  \centering
  \caption{Average performance of semantic labeling models for leave one out strategy.}
  	\label{tab:semlab}
  	\begin{tabular}{c|cc|cc} 
  		\hline
  		\multirow{2}{*}{Model} & \multicolumn{2}{c|}{MRR scores} & \multicolumn{2}{c}{Train time ($s$)}\\
  		 & museum & soccer & museum & soccer\\
  		\hline
  		DSL & 0.56 & 0.618 & 156.6 & 36.3\\
 		Serene & 0.866 & 0.827 & 100.6 & 6.8\\
  		\hline
		\end{tabular} 
%\vspace*{-3mm}
\end{table}


%%%
% performance figures
%%%
%%% museum domain
\begin{figure*}[ht]\small
\pgfplotsset{
    small,
    %legend style={legend pos=north east}
    legend style={
        at={(0.01,0.01)},
        anchor=south west,
    },
   }%
\begin{minipage}[b]{.34\linewidth}
\centering
\begin{tikzpicture}[baseline]
\begin{axis}[
		    xlabel={\emph{known semantic models}},
		    ylabel={Performance},
		    xmin=1, xmax=28,
		    ymin=0.2, ymax=0.9,
		    xtick={1,5,10,15,20,25,28},
		    ytick={0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1},
		    legend pos=south east,
		    ymajorgrids=true,
		    grid style=dashed
		]

		\addplot[
		    color=blue,
		    mark=square,
		    ]
		    coordinates {
		    (1,0.477688172043011)(2,0.543722761679028)(3,0.584279525763794)(4,0.560916442048518)(5,0.508442559100454)(6,0.451911027568922)(7,0.560410216718266)(8,0.627540834845735)(9,0.658907184769254)(10,0.494298245614035)(11,0.594547996272134)(12,0.572438909774436)(13,0.643132689678742)(14,0.544147521036133)(15,0.561388900346478)(16,0.620470013199142)(17,0.631330163644405)(18,0.644192377495463)(19,0.642924629016761)(20,0.656325397672681)(21,0.610482642157672)(22,0.628992740471869)(23,0.570074611816898)(24,0.679169187336157)(25,0.673558897243108)(26,0.667890182643746)(27,0.68742147145051)(28,0.709820528332325)
		    };
		\addplot[
		    color=red,
		    mark=*,
		    ]
		    coordinates {
		    (1,0.570063795853269)(2,0.756845238095238)(3,0.621034680606911)(4,0.719615829557505)(5,0.663677414539484)(6,0.680661881977671)(7,0.702849371292569)(8,0.730720679999118)(9,0.715323491375385)(10,0.722695511010729)(11,0.722586065299008)(12,0.725508681952266)(13,0.728214414334958)(14,0.753560036454773)(15,0.778231825645619)(16,0.745982043507288)(17,0.715855206037534)(18,0.733838894506235)(19,0.728435738081271)(20,0.754932383250967)(21,0.76774421230943)(22,0.761660230839754)(23,0.750358005521049)(24,0.82098385331144)(25,0.823507591442374)(26,0.834847535505431)(27,0.84013108540293)(28,0.813133718212162)
		    };
		\addplot[
		    color=green,
		    mark=x,
		    ]
		    coordinates {
		    (1,0.580144743457437)(2,0.699277168494516)(3,0.596982860940987)(4,0.683431847315197)(5,0.634133314342686)(6,0.630169810336433)(7,0.628025663269931)(8,0.642973856209151)(9,0.618457602339181)(10,0.616241290282443)(11,0.606940556177678)(12,0.605471976942706)(13,0.598988030767536)(14,0.608112237561116)(15,0.609841319882303)(16,0.578626150272492)(17,0.55776862026862)(18,0.57760989010989)(19,0.567994505494506)(20,0.492368742368742)(21,0.582722832722833)(22,0.574786324786325)(23,0.644688644688645)(24,0.658424908424909)(25,0.708791208791209)(26,0.716727716727717)(27,0.719373219373219)(28,0.708791208791209)
		    };
		%\legend{karma,serene,serene-pats}

		\end{axis}
\end{tikzpicture}
\subcaption{precision}\label{fig:museumprec}
\end{minipage}%
%
\begin{minipage}[b]{.33\linewidth}
\centering
\begin{tikzpicture}[baseline]
		\begin{axis}[
		    xlabel={\emph{known semantic models}},
		    %ylabel={recall},
		    xmin=1, xmax=28,
		    ymin=0.2, ymax=0.9,
		    xtick={1,5,10,15,20,25,28},
		    ytick={0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1},
		    ymajorgrids=true,
		    grid style=dashed,
		    legend style={at={(0.5,1.1)},anchor=south, legend columns=-1}
		]

		\addplot[
		    color=blue,
		    mark=square,
		    ]
		    coordinates {
		    (1,0.209547221954433)(2,0.411561264822134)(3,0.457295783926219)(4,0.449720026350461)(5,0.414575098814229)(6,0.364575098814229)(7,0.452173913043478)(8,0.526317523056654)(9,0.588158761528327)(10,0.403491436100132)(11,0.506175889328063)(12,0.489690382081687)(13,0.584008563899868)(14,0.470553359683795)(15,0.48570487483531)(16,0.553513584117033)(17,0.553774817136886)(18,0.573236677115987)(19,0.567816091954023)(20,0.580551201671891)(21,0.557301462904911)(22,0.559979101358412)(23,0.477098571926158)(24,0.57088122605364)(25,0.56078021595263)(26,0.565134099616858)(27,0.585336119818878)(28,0.598310693138279)
};
		\addplot[
		    color=red,
		    mark=*,
		    ]
		    coordinates {
		    (1,0.558240946045824)(2,0.733876811594203)(3,0.610770750988142)(4,0.707559288537549)(5,0.654891304347826)(6,0.670421607378129)(7,0.704710144927536)(8,0.729611330698287)(9,0.716913702239789)(10,0.728837285902504)(11,0.724769433465085)(12,0.724670619235837)(13,0.727783267457181)(14,0.76187417654809)(15,0.790283267457181)(16,0.751266980146291)(17,0.72991118077325)(18,0.761259143155695)(19,0.742058516196448)(20,0.759103970741902)(21,0.776149425287357)(22,0.758842737722048)(23,0.730668756530825)(24,0.800330895158482)(25,0.800330895158482)(26,0.808951584813654)(27,0.813305468477882)(28,0.790229885057471)
};
		\addplot[
		    color=green,
		    mark=x,
		    ]
		    coordinates {
		    (1,0.571875702946753)(2,0.770701581027668)(3,0.637285902503294)(4,0.73596837944664)(5,0.677618577075099)(6,0.693148880105402)(7,0.725263504611331)(8,0.750164690382082)(9,0.739640974967062)(10,0.743988801054019)(11,0.742094861660079)(12,0.734420289855072)(13,0.742934782608696)(14,0.775131752305666)(15,0.795965085638999)(16,0.772361546499478)(17,0.752899686520376)(18,0.776671891327064)(19,0.765308254963427)(20,0.733838383838384)(21,0.783986415882968)(22,0.774255485893417)(23,0.751219087425984)(24,0.803030303030303)(25,0.828456983629397)(26,0.83707767328457)(27,0.841431556948798)(28,0.828456983629397)
};
		 %\legend{karma,serene,serene-pats}

		\end{axis}
	\end{tikzpicture}
\subcaption{recall}\label{fig:museumrec}
\end{minipage}%
%
\begin{minipage}[b]{.33\linewidth}
\centering
\begin{tikzpicture}[baseline]
\begin{axis}[
		    xlabel={\emph{known semantic models}},
		    %ylabel={time(s)},
		    xmin=1, xmax=28,
		    ymin=0.0, ymax=8.5,
		    xtick={1,5,10,15,20,25,28},
		    ytick={0.0,1,2,3,4,5,6,7,8},
		    ymajorgrids=true,
		    grid style=dashed,
		    %legend pos=outer north east,
		    %legend style={at={(0.5,-0.1)},anchor=north, legend columns=-1}
		]

		\addplot[
		    color=blue,
		    mark=square,
		    ]
		    coordinates {
		    (1,0.28413987159729)(2,0.598592698574067)(3,0.36263108253479)(4,0.400362551212311)(5,0.387216985225677)(6,0.392432987689972)(7,0.394440889358521)(8,0.430805265903473)(9,0.438177883625031)(10,0.441894292831421)(11,0.461780428886414)(12,0.469180881977081)(13,0.477133095264435)(14,0.498149693012238)(15,0.512342214584351)(16,0.600962460041046)(17,0.5725257396698)(18,0.907191514968871)(19,0.551609396934509)(20,0.585879027843475)(21,0.610454380512239)(22,0.575962841510773)(23,0.657813549041748)(24,0.671637773513794)(25,0.689822912216188)(26,0.724388360977171)(27,0.750569899876912)(28,0.771229823430379)
};
		\addplot[
		    color=red,
		    mark=*,
		    ]
		    coordinates {
		    (1,0.0166666666666667)(2,0.995)(3,0.8725)(4,0.8325)(5,0.9175)(6,0.965)(7,0.89)(8,0.9675)(9,0.96)(10,1.1225)(11,1.1475)(12,1.36)(13,1.295)(14,1.3925)(15,1.375)(16,1.4975)(17,1.9575)(18,2.11)(19,1.9075)(20,1.9175)(21,1.865)(22,1.915)(23,2.49)(24,2.4)(25,2.49)(26,2.49)(27,2.68333333333333)(28,2.47666666666667)
};
		\addplot[
		    color=green,
		    mark=x,
		    ]
		    coordinates {
		    (1,0.025)(2,1.0375)(3,0.93)(4,1)(5,0.9575)(6,0.9425)(7,0.9)(8,0.975)(9,1.06)(10,1.2025)(11,1.2975)(12,1.9425)(13,1.52)(14,2.2825)(15,1.6275)(16,3.5375)(17,2.255)(18,2.1625)(19,6.505)(20,1.44666666666667)(21,2.2825)(22,2.3475)(23,8.28666666666667)(24,1.895)(25,8.3)(26,3.75333333333333)(27,3.73)(28,3.75)
};
		 %\legend{karma,serene,serene-pats}

		\end{axis}
\end{tikzpicture}
\subcaption{time (s)}\label{fig:museumtime}
\end{minipage}%
\caption{Average precision, recall and time on the museum domain for \relonto{} systems with variable training set size.}\label{fig:perfmuseum}
\end{figure*}

%%% soccer domain
\begin{figure*}[ht]\small
\pgfplotsset{
    small,
    %legend style={legend pos=north east}
    legend style={
        at={(0.01,0.01)},
        anchor=south west,
    },
   }%
\begin{minipage}[b]{.34\linewidth}
\centering
\begin{tikzpicture}[baseline]
\begin{axis}[
		    xlabel={\emph{known semantic models}},
		    ylabel={Performance},
		    xmin=1, xmax=11,
		    ymin=0.5, ymax=0.9,
		    xtick={1,2,4,6,8,10,11},
		    ytick={0.5,0.6,0.7,0.8,0.9,1},
		    legend pos=south east,
		    ymajorgrids=true,
		    grid style=dashed
		]

		\addplot[
		    color=blue,
		    mark=square,
		    ]
		    coordinates {
		    (1,0.635191626901633)(2,0.549997502815009)(3,0.675720834727361)(4,0.719693253328935)(5,0.759169846724195)(6,0.760054331456753)(7,0.800812140122402)(8,0.812192030050689)(9,0.799552066440611)(10,0.821470975418344)(11,0.785878855002637)
		    };
		\addplot[
		    color=red,
		    mark=*,
		    ]
		    coordinates {
		    (1,0.676934852587026)(2,0.61473599870339)(3,0.723937079602602)(4,0.786238815638129)(5,0.777035817669233)(6,0.781984613615049)(7,0.81368099248534)(8,0.817013725291758)(9,0.816270530687007)(10,0.846744827831784)(11,0.852649148301322)
		    };
		\addplot[
		    color=green,
		    mark=x,
		    ]
		    coordinates {
		    (1,0.66759959719914)(2,0.629014687197419)(3,0.692208378950833)(4,0.744652988406557)(5,0.773486992410165)(6,0.756607637648352)(7,0.803820434917082)(8,0.793054493090329)(9,0.792256229657042)(10,0.822093203062231)(11,0.828181360184871)
		    };
		%\legend{karma,serene,serene-pats}

		\end{axis}
\end{tikzpicture}
\subcaption{precision}\label{fig:soccerprec}
\end{minipage}%
%
\begin{minipage}[b]{.33\linewidth}
\centering
\begin{tikzpicture}[baseline]
		\begin{axis}[
		    xlabel={\emph{known semantic models}},
		    %ylabel={recall},
		    xmin=1, xmax=11,
		    ymin=0.3, ymax=0.9,
		    xtick={1,2,4,6,8,10,11},
		    ytick={0.3,0.4,0.5,0.6,0.7,0.8,0.9,1},
		    ymajorgrids=true,
		    grid style=dashed,
		    legend style={at={(0.5,1.1)},anchor=south, legend columns=-1}
		]

		\addplot[
		    color=blue,
		    mark=square,
		    ]
		    coordinates {
		    (1,0.444761527680188)(2,0.372447158105053)(3,0.545528381345078)(4,0.596008831526073)(5,0.6499887923799)(6,0.643884492868159)(7,0.685035675993026)(8,0.702870161195933)(9,0.654001538724769)(10,0.685153350715964)(11,0.662999993217779)
		    };
		\addplot[
		    color=red,
		    mark=*,
		    ]
		    coordinates {
		    (1,0.690636806043505)(2,0.613080486764697)(3,0.72563707600459)(4,0.780625908674911)(5,0.776616927805676)(6,0.779496772132888)(7,0.813459305700685)(8,0.813245834960899)(9,0.810586300672508)(10,0.84298404022542)(11,0.849899398175261)
		    };
		\addplot[
		    color=green,
		    mark=x,
		    ]
		    coordinates {
		    (1,0.689786194666577)(2,0.655399210040359)(3,0.719915653815835)(4,0.776231754935929)(5,0.802770096610387)(6,0.787355423564135)(7,0.838616573256072)(8,0.82175912881902)(9,0.821414409345444)(10,0.851497334083541)(11,0.85656084018153)
		    };
		 \legend{karma,serene,serene-pats}

		\end{axis}
	\end{tikzpicture}
\subcaption{recall}\label{fig:soccerrec}
\end{minipage}%
%
\begin{minipage}[b]{.33\linewidth}
\centering
\begin{tikzpicture}[baseline]
\begin{axis}[
		    xlabel={\emph{known semantic models}},
		    %ylabel={time(s)},
		    xmin=1, xmax=11,
		    ymin=0.0, ymax=0.3,
		    xtick={1,2,4,6,8,10,11},
		    ytick={0.0,0.1,0.2},
		    ymajorgrids=true,
		    grid style=dashed,
		    %legend pos=outer north east,
		    %legend style={at={(0.5,-0.1)},anchor=north, legend columns=-1}
		]

		\addplot[
		    color=blue,
		    mark=square,
		    ]
		    coordinates {
		    (1,0.107354099100286)(2,0.137003461519877)(3,0.163627962271372)(4,0.17774627606074)(5,0.179288367430369)(6,0.183507978916168)(7,0.189805428187052)(8,0.191188136736552)(9,0.196139633655548)(10,0.200133164723714)(11,0.218581974506378)
		    };
		\addplot[
		    color=red,
		    mark=*,
		    ]
		    coordinates {
		    (1,0.0595748017051003)(2,0.0895205450057983)(3,0.0976518734296163)(4,0.103216880957286)(5,0.108438626130422)(6,0.115763804117839)(7,0.125697635014852)(8,0.118865826924642)(9,0.119359710216522)(10,0.123752357959747)(11,0.153613630930583)
		    };
		\addplot[
		    color=green,
		    mark=x,
		    ]
		    coordinates {
		    (1,0.0687879033522172)(2,0.0874820310419256)(3,0.103948153495789)(4,0.104214943885803)(5,0.115242712974548)(6,0.126150580406189)(7,0.122052125063809)(8,0.128753701051076)(9,0.129606107076009)(10,0.13165650844574)(11,0.142413517634074)
		    };
		 %\legend{karma,serene,serene-pats}

		\end{axis}
\end{tikzpicture}
\subcaption{time (s)}\label{fig:soccertime}
\end{minipage}%
\caption{Average precision, recall and time on the soccer domain for \relonto{} systems with variable training set size.}\label{fig:perfsoccer}
\end{figure*}

% karma vs serene vs serene-pats
We evaluate our new system \emph{serene} and its modification \emph{serene-pats}, which uses graph patterns, against the state-of-the-art system \emph{karma}.
All three systems have access to the same set of matches produced by our semantic labeling model.
Fig.~\ref{fig:perfmuseum} and~\ref{fig:perfsoccer} show their performance on the museum and soccer domains.
We report average precision, recall and run times for the systems with regard to variable number of semantic models in the training set.
For \emph{serene} and \emph{serene-pats} we report the first solutions found by the chuffed solver.
We use default parameters for \emph{karma} which were shown to yield the best results~\cite{taheriyan2016learning}.
As we can see, \emph{serene} produces on average the best semantic models in terms of precision while \emph{serene-pats} generates slightly better models in terms of recall.
If we consider results separately per each instance and not on average, there are a few instances where \emph{karma} generates more precise models, however, our new approaches produce much better models in terms of recall in all considered instances. 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%% sequentially found solutions and different weights for patterns
\begin{figure*}[h]\small
\pgfplotsset{
    small,
    %legend style={legend pos=north east}
    legend style={
        at={(0.01,0.01)},
        anchor=south west,
    },
   }%
\begin{minipage}[b]{.34\linewidth}
\centering
\begin{tikzpicture}[baseline]
\begin{axis}[
		    xlabel={\emph{solution}},
		    ylabel={Performance},
		    xmin=0, xmax=20,
		    ymin=0.7, ymax=1,
		    xtick={0,5,10,15,20},
		    ytick={0.7,0.8,0.9,1},
		    legend pos=south east,
		    ymajorgrids=true,
		    grid style=dashed,
		    legend style={at={(1.5,1.1)},anchor=south, legend columns=-1}
		]

		\addplot[
		    color=blue,
		    mark=square,
		    ]
		    coordinates {
		    (0,0.813133718212162)(1,0.870689655172414)(2,0.869565217391304)(3,0.854700854700855)(4,0.847457627118644)(5,0.862068965517241)(6,0.862068965517241)(7,0.860869565217391)
		    };
		\addplot[
		    color=red,
		    mark=*,
		    ]
		    coordinates {
		    (0,0.708791208791209)(1,0.720429778415431)(2,0.727852084972463)(3,0.734756097560976)(4,0.737969058591178)(5,0.723003960808839)(6,0.727905921593153)(7,0.740887177292826)(8,0.733003960808839)(9,0.746193299741805)(10,0.73554304773817)(11,0.74569890495285)(12,0.756325773784054)(13,0.745676961413577)(14,0.753615746683783)(15,0.7306060898002)(16,0.723882805154582)(17,0.720774744968293)(18,0.733079110976868)(19,0.731544715447155)(20,0.734034752112227)

		    };
		\addplot[
		    color=green,
		    mark=x,
		    ]
		    coordinates {
		    (0,0.71031746031746)(1,0.722023912003826)(2,0.734193548387097)(3,0.740054370716392)(4,0.751788722391459)(5,0.752652119278914)(6,0.765286464150101)(7,0.766275317871063)(8,0.763956676916058)(9,0.779373522458629)(10,0.780497706328908)(11,0.786846912678115)(12,0.793409626193882)(13,0.801554001554001)(14,0.800878033205619)(15,0.861352657004831)(16,0.863636363636364)(17,0.863636363636364)(18,0.883720930232558)(19,0.8125)(20,0.795918367346939)
		    };
		\addplot[
		    color=brown,
		    mark=+,
		    ]
		    coordinates {
		    (0,0.71031746031746)(1,0.722023912003826)(2,0.734193548387097)(3,0.740054370716392)(4,0.751788722391459)(5,0.752652119278914)(6,0.758342019705656)(7,0.772281323877069)(8,0.774638933587619)(9,0.786846912678115)(10,0.786846912678115)(11,0.795363644516187)(12,0.804524886877828)(13,0.797201562617384)(14,0.812955643390426)(15,0.775568181818182)(16,0.863636363636364)(17,0.883720930232558)(18,0.883720930232558)(19,0.883720930232558)(20,0.904761904761905)
};
		 \addplot[
		    color=violet,
		    mark=star,
		    ]
		    coordinates {
		    (0,0.716727716727717)(1,0.728559859716244)(2,0.740860215053763)(3,0.746857091804827)(4,0.757315933275812)(5,0.758342019705656)(6,0.765286464150101)(7,0.779373522458629)(8,0.787744083140503)(9,0.786846912678115)(10,0.789244481875285)(11,0.804524886877828)(12,0.811442006269593)(13,0.803401771336554)(14,0.785524847694936)(15,0.849173553719008)(16,0.852651515151516)(17,0.866230213015439)(18,0.876750700280112)(19,0.85593220338983)(20,0.863247863247863)
};
		\legend{serene,pats-1,pats-5,pats-10,pats-20}

		\end{axis}
\end{tikzpicture}
\subcaption{precision}\label{fig:solprec}
\end{minipage}%
%
\begin{minipage}[b]{.33\linewidth}
\centering
\begin{tikzpicture}[baseline]
		\begin{axis}[
		    xlabel={\emph{solution}},
		    %ylabel={recall},
		    xmin=0, xmax=20,
		    ymin=0.7, ymax=1,
		    xtick={0,5,10,15,20},
		    ytick={0.7,0.8,0.9,1},
		    ymajorgrids=true,
		    grid style=dashed,
		    %legend style={at={(0.5,1.1)},anchor=south, legend columns=-1}
		]

		\addplot[
		    color=blue,
		    mark=square,
		    ]
		    coordinates {
		    (0,0.790229885057471)(1,0.870689655172414)(2,0.862068965517241)(3,0.862068965517241)(4,0.862068965517241)(5,0.862068965517241)(6,0.862068965517241)(7,0.853448275862069)
		    };
		\addplot[
		    color=red,
		    mark=*,
		    ]
		    coordinates {
		    (0,0.828456983629397)(1,0.828456983629397)(2,0.828456983629397)(3,0.828456983629397)(4,0.828456983629397)(5,0.82088122605364)(6,0.82088122605364)(7,0.823754789272031)(8,0.82088122605364)(9,0.823754789272031)(10,0.841431556948798)(11,0.841431556948798)(12,0.841431556948798)(13,0.835684430512017)(14,0.838557993730407)(15,0.825583420411007)(16,0.810431905259492)(17,0.82088122605364)(18,0.82088122605364)(19,0.83098223615465)(20,0.833855799373041)
};
		\addplot[
		    color=green,
		    mark=x,
		    ]
		    coordinates {
		    (0,0.83098223615465)(1,0.83098223615465)(2,0.83098223615465)(3,0.823406478578892)(4,0.828108672936259)(5,0.820532915360502)(6,0.828108672936259)(7,0.820532915360502)(8,0.820532915360502)(9,0.828108672936259)(10,0.820532915360502)(11,0.820532915360502)(12,0.818007662835249)(13,0.810431905259492)(14,0.800330895158482)(15,0.867163009404389)(16,0.863636363636364)(17,0.863636363636364)(18,0.863636363636364)(19,0.886363636363636)(20,0.886363636363636)
};
		 \addplot[
		    color=brown,
		    mark=+,
		    ]
		    coordinates {
		    (0,0.83098223615465)(1,0.83098223615465)(2,0.83098223615465)(3,0.823406478578892)(4,0.828108672936259)(5,0.820532915360502)(6,0.820532915360502)(7,0.820532915360502)(8,0.820532915360502)(9,0.820532915360502)(10,0.820532915360502)(11,0.820532915360502)(12,0.820532915360502)(13,0.810431905259492)(14,0.810431905259492)(15,0.765151515151516)(16,0.863636363636364)(17,0.863636363636364)(18,0.863636363636364)(19,0.863636363636364)(20,0.863636363636364)
};
		 \addplot[
		    color=violet,
		    mark=star,
		    ]
		    coordinates {
		    (0,0.838557993730407)(1,0.838557993730407)(2,0.838557993730407)(3,0.83098223615465)(4,0.828108672936259)(5,0.820532915360502)(6,0.828108672936259)(7,0.828108672936259)(8,0.828108672936259)(9,0.820532915360502)(10,0.820532915360502)(11,0.820532915360502)(12,0.818007662835249)(13,0.800330895158482)(14,0.790229885057471)(15,0.867163009404389)(16,0.867163009404389)(17,0.867163009404389)(18,0.867163009404389)(19,0.870689655172414)(20,0.870689655172414)
};	
	%\legend{serene,pats-1,pats-5,pats-10,pats-20}
		\end{axis}
	\end{tikzpicture}
\subcaption{recall}\label{fig:solrec}
\end{minipage}%
%
\begin{minipage}[b]{.33\linewidth}
\centering
\begin{tikzpicture}[baseline]
\begin{axis}[
		    xlabel={\emph{solution}},
		    %ylabel={time(s)},
		    xmin=0, xmax=20,
		    ymin=0.0, ymax=21,
		    xtick={0,5,10,15,20},
		    ytick={0.0,3.0,6.0,9.0,12,15.0,18,21.0},
		    ymajorgrids=true,
		    grid style=dashed,
		    %legend pos=outer north east,
		    %legend style={at={(0.5,-0.1)},anchor=north, legend columns=-1}
		]

		\addplot[
		    color=blue,
		    mark=square,
		    ]
		    coordinates {
		    (0,2.47666666666667)(1,7.15)(2,7.41)(3,8.83)(4,9.15)(5,9.32)(6,9.84)(7,10.04)
};
		\addplot[
		    color=red,
		    mark=*,
		    ]
		    coordinates {
		    (0,3.75)(1,3.8)(2,3.84)(3,3.88666666666667)(4,3.93333333333333)(5,3.98)(6,4.03333333333333)(7,4.08)(8,4.13333333333333)(9,4.23)(10,4.29333333333333)(11,4.34)(12,4.38666666666667)(13,4.74)(14,4.83)(15,5.74333333333333)(16,5.96333333333333)(17,6.48666666666667)(18,6.53)(19,6.58333333333333)(20,6.63)
};
		\addplot[
		    color=green,
		    mark=x,
		    ]
		    coordinates {
		    (0,3.74)(1,3.79)(2,3.83666666666667)(3,3.88666666666667)(4,3.93666666666667)(5,3.98666666666667)(6,4.03666666666667)(7,4.09333333333333)(8,4.17333333333333)(9,4.23)(10,4.31666666666667)(11,4.38)(12,4.54333333333333)(13,5)(14,6.17666666666667)(15,6.755)(16,1.61)(17,2.21)(18,2.35)(19,2.61)(20,3.11)
};
		\addplot[
		    color=brown,
		    mark=+,
		    ]
		    coordinates {
		    (0,3.75)(1,3.8)(2,3.84666666666667)(3,3.89666666666667)(4,3.95)(5,3.99666666666667)(6,4.05)(7,4.10333333333333)(8,4.16666666666667)(9,4.23333333333333)(10,4.43)(11,4.53333333333333)(12,4.78)(13,5.15333333333333)(14,5.36333333333333)(15,3.365)(16,1.91)(17,1.95)(18,8.42)(19,8.62)(20,8.85)
};
		 \addplot[
		    color=violet,
		    mark=star,
		    ]
		    coordinates {
		    (0,3.73666666666667)(1,3.78666666666667)(2,3.83666666666667)(3,3.88333333333333)(4,3.93666666666667)(5,3.98666666666667)(6,4.04333333333333)(7,4.09666666666667)(8,4.16)(9,4.22)(10,4.38333333333333)(11,4.49)(12,4.72333333333333)(13,4.99333333333333)(14,9.33333333333333)(15,10.715)(16,10.86)(17,10.915)(18,12.65)(19,20.35)(20,20.56)
};	
	%\legend{serene,pats-1,pats-5,pats-10,pats-20}
		\end{axis}
\end{tikzpicture}
\subcaption{time (s)}\label{fig:soltime}
\end{minipage}%
\caption{Average precision, recall and time on the museum domain for leave-one-out strategy and different weighting scheme for patterns in serene.}\label{fig:perfsol}
\end{figure*}

%% sequential solution
As mentioned previously, the chuffed solver outputs solutions as it finds them.
In Fig.~\ref{fig:perfmuseum} and~\ref{fig:perfsoccer} we report the first found solutions.
In Fig.~\ref{fig:perfsol} we show how the performance of \emph{serene} changes across sequentially found solutions.
The idea is that the chuffed solver finds better solutions in terms of cost function, however, as we can see from the results,
that does not translate directly into more precise semantic models.
Additionally, we investigate how the performance is influenced if we introduce a weighting scheme on the patterns,
i.e., costs of patterns are scaled by a factor.
In Fig.~\ref{fig:perfmuseum} and~\ref{fig:perfsoccer} we use a scaling factor 1 for pattern costs.
Fig.~\ref{fig:perfsol} demonstrates that by using scaling factors 5, 10 or 20 for patterns from the museum domain we can generate semantic models which are almost 90\% in precision and recall.
This is a 20\% improvement in presision compared to the first solution found by \emph{serene-pats} and a 10\% improvement both in precision and recall for the first solution from \emph{serene}.
However, such improvement comes at a cost in run time.
On average, we have observed that the chuffed solver yields very good results already with the first found solution.
The sequential solutions are not always better, and hitting the optimal solution may take hours.


% change in performance if we look at sequentially found solutions
% only leave-one-out for museum domain with 15s timeout for chuffed
\npr{not sure whether Fig.~\ref{fig:loo} is needed}
\begin{figure}\small
\begin{tikzpicture}\small
\pgfplotsset{
    scale only axis,
    small,
    xmin=0, xmax=9
}

\begin{axis}[
  axis y line*=left,
  ymin=0.5, ymax=1,
  xlabel=solution number,
  ylabel=performance,
  legend pos=south east,
]
\addplot[smooth,mark=x,red]
  coordinates{
    (0,0.776507549540743)(1,0.71093042754513)(2,0.822783653218436)(3,0.845760233918129)(4,0.879310344827586)(5,0.88695652173913)(6,0.885964912280702)(7,0.870689655172414)(8,0.878260869565217)(9,0.87719298245614)

}; \label{plot_one}
\addlegendentry{precision}
\addplot[smooth,mark=*,green]
  coordinates{
    (0,0.773180507486795)(1,0.677202255831871)(2,0.805899400726987)(3,0.838122605363985)(4,0.879310344827586)(5,0.879310344827586)(6,0.870689655172414)(7,0.870689655172414)(8,0.870689655172414)(9,0.862068965517241)
}; \label{plot_two}
\addlegendentry{recall}
\end{axis}

\begin{axis}[
  axis y line*=right,
  axis x line=none,
  ymin=0, ymax=15,
  legend pos=south east,
  ylabel=time (s)
]
\addlegendimage{/pgfplots/refstyle=plot_one}\addlegendentry{precision}
\addlegendimage{/pgfplots/refstyle=plot_two}\addlegendentry{recall}
\addplot[smooth,mark=square,blue]
  coordinates{
    (0,0.894338290115883)(1,2.39426428574782)(2,6.89703391393025)(3,10.3563708686829)(4,9.87668780326843)(5,9.92719115257263)(6,10.4045292949677)(7,14.3818371582031)(8,14.4026180458069)(9,14.8023208427429)
}; \addlegendentry{time}
\end{axis}
\end{tikzpicture}
\caption{Performance of \emph{serene} for leave-one-out strategy on the museum domain.}\label{fig:loo}
\end{figure}

\npr{Maybe some words on how optimal solution found by chuffed relates to the ground truth?}

\section{Related Work \label{SEC:pw}}
\ddg{rewrite, add more}
\npr{Now the opposite problem}

Relational data sources are still one of the most popular ways to store enterprise or Web data, however, the issue with relational schema is the lack of a well-defined semantic description.
A common ontology provides a way to represent the meaning of a relational schema and can facilitate the integration of heterogeneous data sources within a domain.
Indicating semantic correspondences manually might be appropriate if only few data sources need to be integrated, however, it becomes tedious with the growing number of heterogeneous schemata.
Hence, automatic or semi-automatic approaches for relational-to-ontology schema mapping are being actively developed.


The majority of approaches to solve the relational-to-ontology (\relonto{}) mapping problem are based on heuristic rules and alignment of constraints specified within relational schemata and ontologies.
A very comprehensive overview and comparison of existing mapping generation tools based on this approach is given in~\cite{Pinkel:rodi} and~\cite{Spanos:semweb}.
As examples, there are BootOX~\cite{Jimenez:Bootox}, MIRROR~\cite{Luciano:Mirror} and  ontop~\cite{Fagin:Clio}.
Crudely speaking, these tools first apply a default direct mapping specified by the W3C.
Further, the default ontology is enriched by using explicit and implicit schema constraints.
Finally, ontology alignment techniques are applied to match the default ontology to the target ontology.
The main advantage of these systems is the ability to run in a fully automatic setting.
Our approach is complementary to the approaches from this group and at its current stage is semi-automatic.
However, constraint programming offers a convenient framework to incorporate integrity constraints specified either within relational or ontological schema as additional constraints to govern the search for the solution.
This opens an interesting direction for further research to develop an automatic system.

A major issue with fully automatic systems is though that constraints may be inconsistent or absent completely, e.g., data from Web services or tables on the Web \ddg{Why?}.
To overcome this issue, we can apply ML techniques.
\cite{Limaye:Annotating} design a system to annotate web tables with entities for cell values, semantic labels for attributes and relationships for binary combinations of attributes.
As in our approach, they decompose the process of mapping into two main stages: semantic labeling and finding relationships between matched semantic labels.
\cite{Limaye:Annotating} enrich their data sources by using YAGO.
\cite{Mulwad:Semantic} extend this approach by leveraging information from Wikitology Knowledge Base (KB).
\cite{Venetis:Recovering} develop a scalable approach to recover the semantics of Web tables by incorporating data from the isA database KB.
\cite{Ritze:matching}, on the other hand, use DBPedia as their KB.
%extract additional data from knowledge bases to assign a semantic label to an attribute.
Hence, these approaches are limited to domains well represented in those knowledge bases.
Also, they are not able to find the relation between attributes in the table if there is no direct connection between the attributes.
Our approach, on the other hand, allows a model to be trained on any data and can infer complex semantic paths which might exist between attributes.
However, it might be further bootstrapped by leveraging external knowledge bases.
This is especially beneficial at the start when the system does not have sufficient training data.

As mentioned above, the approaches for mapping Web tables also perform semantic labeling.
They design various similarity metrics for attribute names and values.
However, they disregard the attributes which are not matched to the ontology (the so-called \emph{unknown} set of attributes) which are especially abundant on the Web~\cite{Ritze:matching}\cite{Pham:semantic}.
It is clear that we cannot directly speak about similarity for unmatched attributes, since they are rather dissimilar from known semantic types.
That is why we have developed a new approach for semantic labeling which can efficiently handle the \emph{unknown} class.
We demonstrate its efficiency by comparing against the state-of-the-art approach DSL~\cite{Pham:semantic}.

We build upon the work of~\cite{taheriyan2016learning} and use their ideas for the construction of the alignment graph.
The only difference is that we introduce the \emph{unknown} and \emph{root} class nodes and as many \emph{unknown} data nodes as there are attributes in the modeled data source.
These nodes serve to capture the unmatched attributes from the source.
Though we have modified Karma to treat these additional nodes as well, our approach outperforms Karma since we have additional constraints for these nodes and use an exact algorithm to solve the STP.
\cite{taheriyan2016learning} treat the matching and STP parts of \relonto{} independently and use heuristic algorithms for both.
We, on the other hand, use exact algorithms for both parts and address them within a unified CP model.

In their follow up work, \cite{Taheriyan:Leveraging} suggest to use graph patterns to boost the performance of their system.
To perform semantic modeling in such scenario, \cite{Taheriyan:Leveraging} had to revise their algorithm by introducing additional heuristics.
However, in our case we had to add pattern variables and to modify the objective function in the MiniZinc model.
No changes to the solver were required.
This makes our system very convenient and opens directions for validating various additional constraints.
Though our approach beats the state-of-the-art system Karma in the conducted experiments, it is worth noting that the scalability of our approach is under question.
The main argument why exact solution for STP is feasible in our setting is that we map data sources to a domain-specific ontology which is expected to be limited in its size.

\ddg{Isn't this really similar??}
\npr{It is very similar, I'm even using their code partially :)}

\section{Conclusion}
\ddg{TODO} 
In this paper we have introduced a new approach to solve the problem of relational-to-ontology schema mapping.

Future directions:
incorporate Linked Open Data and other external knowledge bases to overcome cold start problem;
incorporate schema and ontology constraints;
complex matches like 1:n and n:1 and iMap.

\bibliographystyle{aaai}
\npr{TODO: shorten citations like conference names and if there are more than 4 authors use et al}
\bibliography{main}
\end{document}
